标题: Python爬取西刺国内高匿代理ip并验证
博文链接: https://blog.csdn.net/oscer2016/article/details/75000148
发布时间: 2017年07月11日 23:09:17

正文: 1.抓取ip存入文件首先，我们访问西刺首页 http://www.xicidaili.com/，并点击国内高匿代理，如下图:按 F12 检查网页元素或者 ctrl+u查看网页源代码:我们需要提取的是 ip 和端口，这里我们用正则提取，代码如下:# -*- coding:utf8 -*-

import urllib2
import re
import time

headers = {
    'Accept': '*/*',
    'Accept-Language': 'zh-CN,zh;q=0.8',
    'User-Agent': 'Mozilla/5.0 (X11; Fedora; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36',
    'Hosts': 'hm.baidu.com',
    'Referer': 'http://www.xicidaili.com/nn',
    'Connection': 'keep-alive'
}

# 指定爬取范围（这里是第1~1000页）
for i in range(1,1000):

    url = 'http://www.xicidaili.com/nn/' + str(i)
    req = urllib2.Request(url=url,headers=headers)
    res = urllib2.urlopen(req).read()

    # 提取ip和端口
    ip_list = re.findall("(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}).*?(\d{2,6})", res, re.S)

    # 将提取的ip和端口写入文件
    f = open("ip.txt","a+")
    for li in ip_list:
        ip = li[0] + ':' + li[1] + '\n'
        print ip
        f.write(ip)

    time.sleep(2)       # 每爬取一页暂停两秒2.提取可用ip并存入文件  刚才爬取的 ip 有大量都是不可用的，我们需要将可用的 ip 提取出来，这里我们使用站长之家的 ip 查询 http://ip.chinaz.com/, 如下图:代码如下:# -*- coding:utf8 -*-

import urllib
import socket
socket.setdefaulttimeout(3)

inf = open("ip.txt")    # 这里打开刚才存ip的文件
lines = inf.readlines()
proxys = []
for i in range(0,len(lines)):
    proxy_host = "http://" + lines[i]
    proxy_temp = {"http":proxy_host}
    proxys.append(proxy_temp)

# 用这个网页去验证，遇到不可用ip会抛异常
url = "http://ip.chinaz.com/getip.aspx"
# 将可用ip写入valid_ip.txt
ouf = open("valid_ip.txt", "a+")

for proxy in proxys:
    try:
        res = urllib.urlopen(url,proxies=proxy).read()
        valid_ip = proxy['http'][7:]
        print 'valid_ip: ' + valid_ip
        ouf.write(valid_ip)
    except Exception,e:
        print proxy
        print e
        continue至此，可用 ip 已成功写入文件.